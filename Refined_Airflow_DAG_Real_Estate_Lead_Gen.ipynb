{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VegasCryptoAgent/AI-Agents/blob/main/Refined_Airflow_DAG_Real_Estate_Lead_Gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Imports ---\n",
        "import pendulum\n",
        "import os\n",
        "import json\n",
        "import logging\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "# Airflow specific imports\n",
        "from airflow.decorators import dag, task\n",
        "from airflow.models.dagrun import DagRun\n",
        "from airflow.models.param import Param\n",
        "from airflow.exceptions import AirflowSkipException, AirflowFailException\n",
        "\n",
        "# AI SDK imports - Ensure 'airflow-ai-sdk[openai,duckduckgo]' is installed\n",
        "# Or install providers for other models you might use (e.g., anthropic, google-generativeai)\n",
        "import airflow_ai_sdk as ai_sdk\n",
        "from pydantic_ai import Agent\n",
        "from pydantic_ai.common_tools.duckduckgo import duckduckgo_search_tool\n",
        "# You might need to install tool dependencies: pip install duckduckgo-search\n",
        "\n",
        "# --- Configuration ---\n",
        "# IMPORTANT: Configure LLM API Keys via Airflow Connections!\n",
        "# Example: Create an 'openai_default' connection in the Airflow UI (Admin -> Connections)\n",
        "# The SDK will automatically look for relevant connections based on the model provider.\n",
        "# Ensure necessary Python libraries for your chosen models are installed (e.g., 'openai')\n",
        "\n",
        "# Define the output path for the report (adjust as needed for your environment)\n",
        "# This path is relative to where the Airflow task executes. For production,\n",
        "# consider writing to cloud storage (S3, GCS) or a database.\n",
        "REPORT_OUTPUT_DIR = \"/opt/airflow/reports\" # Example path, ensure it exists/is writable by Airflow worker\n",
        "REPORT_FILENAME = \"las_vegas_real_estate_report.json\"\n",
        "\n",
        "# --- Define Pydantic Models for Structured Output ---\n",
        "class ContentIdeas(ai_sdk.BaseModel):\n",
        "    \"\"\"Represents content ideas based on research.\"\"\"\n",
        "    blog_post_titles: List[str]\n",
        "    social_media_snippets: List[str]\n",
        "    target_keywords: List[str]\n",
        "\n",
        "class ResearchReport(ai_sdk.BaseModel):\n",
        "    \"\"\"Structured report combining research and content ideas.\"\"\"\n",
        "    research_query: str\n",
        "    research_summary: str\n",
        "    content_ideas: ContentIdeas\n",
        "    report_generated_at: str # ISO format timestamp\n",
        "\n",
        "# --- Define AI Agents ---\n",
        "\n",
        "# Agent for researching market trends\n",
        "# This agent uses DuckDuckGo to search the web.\n",
        "# Ensure the model name matches your Airflow Connection and installed libraries.\n",
        "research_agent = Agent(\n",
        "    model=\"gpt-4o-mini\", # Example: Use OpenAI. Requires 'openai' library and connection.\n",
        "    system_prompt=\"\"\"\n",
        "    You are a real estate market research assistant specializing in Las Vegas, Nevada.\n",
        "    Your goal is to find the latest (within the past month) news, articles, and reliable discussions\n",
        "    about the Las Vegas housing market. Focus on trends, prices, inventory levels, popular neighborhoods\n",
        "    (like Summerlin, Henderson, Downtown), and key reasons people are moving to/from the area.\n",
        "    Use the provided search tool efficiently. Synthesize the findings into a concise,\n",
        "    informative summary (approx. 200-300 words) suitable for informing content strategy.\n",
        "    \"\"\",\n",
        "    tools=[duckduckgo_search_tool()],\n",
        "    # Optional: Add parameters like temperature=0.7 if needed\n",
        ")\n",
        "\n",
        "# --- Airflow DAG Definition ---\n",
        "\n",
        "@dag(\n",
        "    schedule=\"@weekly\", # Run once a week (adjust schedule as needed)\n",
        "    start_date=pendulum.datetime(2025, 4, 1, tz=\"UTC\"), # Use a relevant start date\n",
        "    catchup=False, # Don't run for past missed schedules\n",
        "    tags=[\"ai\", \"real_estate\", \"lead_gen\", \"las_vegas\"],\n",
        "    doc_md=\"\"\"\n",
        "    ### Las Vegas Real Estate Lead Generation DAG\n",
        "\n",
        "    This DAG uses AI agents orchestrated by Airflow to:\n",
        "    1.  **Research Market:** Uses an AI agent with web search capabilities (`@task.agent`)\n",
        "        to gather current information about the Las Vegas real estate market.\n",
        "    2.  **Generate Content Ideas:** Uses an LLM task (`@task.llm`) to brainstorm blog titles,\n",
        "        social media snippets, and keywords based on the research.\n",
        "    3.  **Report Findings:** Saves the combined research and content ideas into a JSON file.\n",
        "\n",
        "    **Configuration:**\n",
        "    * Requires Airflow Connections for the chosen LLM provider (e.g., `openai_default`).\n",
        "    * Ensure necessary Python libraries (`airflow-ai-sdk`, LLM providers, tools) are installed.\n",
        "    * The output report is saved locally by default; modify `report_findings` for production storage.\n",
        "    \"\"\",\n",
        "    params={ # Allow manual trigger with custom query\n",
        "        \"research_query_override\": Param(\n",
        "            type=[\"null\", \"string\"],\n",
        "            default=None,\n",
        "            description=\"Optional: Specify a custom research query instead of the default.\",\n",
        "        ),\n",
        "        \"output_filename_override\": Param(\n",
        "            type=[\"null\", \"string\"],\n",
        "            default=None,\n",
        "            description=\"Optional: Specify a custom output filename (e.g., 'report_YYYYMMDD.json').\",\n",
        "        )\n",
        "     }\n",
        ")\n",
        "def real_estate_lead_gen_dag_refined():\n",
        "    \"\"\"\n",
        "    Airflow DAG for Las Vegas Real Estate Market Research and Content Idea Generation.\n",
        "    \"\"\"\n",
        "\n",
        "    @task.agent(agent=research_agent, result_type=str)\n",
        "    def research_las_vegas_market(dag_run: DagRun = None) -> str:\n",
        "        \"\"\"\n",
        "        Task to perform web research on the Las Vegas real estate market.\n",
        "        Uses the research_agent defined above. Handles basic errors.\n",
        "        \"\"\"\n",
        "        # Determine the query\n",
        "        query = dag_run.conf.get(\"research_query_override\") if dag_run else None\n",
        "        if not query:\n",
        "            query = \"Las Vegas real estate market trends, news, and moving statistics recent month\"\n",
        "\n",
        "        logging.info(f\"Researching market with query: {query}\")\n",
        "\n",
        "        try:\n",
        "            # The agent execution happens here. The SDK handles the call.\n",
        "            # The function just needs to return the input for the agent.\n",
        "            return query\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during agent execution for query '{query}': {e}\", exc_info=True)\n",
        "            # Fail the task explicitly on error\n",
        "            raise AirflowFailException(f\"Agent execution failed: {e}\")\n",
        "\n",
        "    @task.llm(\n",
        "        model=\"gpt-4o-mini\", # Example: Use OpenAI. Requires 'openai' library and connection.\n",
        "        result_type=ContentIdeas, # Expect structured output defined by the Pydantic model\n",
        "        system_prompt=\"\"\"\n",
        "        You are a creative content strategist for a Las Vegas real estate agent.\n",
        "        Based on the provided market research summary, generate engaging and SEO-friendly content ideas\n",
        "        to attract potential buyers and sellers interested in the Las Vegas area.\n",
        "\n",
        "        Produce:\n",
        "        - 3-5 catchy and relevant blog post titles.\n",
        "        - 3-5 short, engaging social media snippets (max 280 chars each) related to the findings.\n",
        "        - A list of 5-10 relevant keywords (including long-tail keywords) to target.\n",
        "\n",
        "        Ensure the ideas are directly inspired by the research summary provided.\n",
        "        Format the output strictly according to the 'ContentIdeas' structure.\n",
        "        \"\"\",\n",
        "    )\n",
        "    def generate_content_ideas_from_research(research_summary: str) -> str:\n",
        "        \"\"\"\n",
        "        Task to generate content ideas using an LLM based on the research summary.\n",
        "        Handles basic errors and validates input.\n",
        "        \"\"\"\n",
        "        if not research_summary or len(research_summary) < 50: # Basic validation\n",
        "             logging.warning(\"Research summary seems too short or empty. Skipping content generation.\")\n",
        "             raise AirflowSkipException(\"Input research summary is insufficient.\")\n",
        "\n",
        "        logging.info(\"Generating content ideas based on research summary...\")\n",
        "        try:\n",
        "            # The LLM call happens here. The SDK handles the call.\n",
        "            # The function just needs to return the input for the LLM.\n",
        "            return research_summary\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during LLM execution for content generation: {e}\", exc_info=True)\n",
        "            # Fail the task explicitly on error\n",
        "            raise AirflowFailException(f\"LLM execution for content ideas failed: {e}\")\n",
        "\n",
        "    @task\n",
        "    def report_findings(research_query: str, research_summary: str, ideas: Dict[str, Any], dag_run: DagRun = None):\n",
        "        \"\"\"\n",
        "        Task to consolidate research and ideas into a structured report (JSON file).\n",
        "\n",
        "        Args:\n",
        "            research_query: The query used for the research task.\n",
        "            research_summary: The summary text generated by the research agent.\n",
        "            ideas: The dictionary representation of the ContentIdeas object from the LLM task.\n",
        "                   Airflow passes Pydantic models as dicts between tasks by default.\n",
        "            dag_run: The current DAG run object to access configuration.\n",
        "        \"\"\"\n",
        "        logging.info(\"Consolidating research and content ideas into a report.\")\n",
        "\n",
        "        try:\n",
        "            # Re-construct the Pydantic model from the dictionary for validation/structure\n",
        "            content_ideas_obj = ContentIdeas(**ideas)\n",
        "\n",
        "            # Get current timestamp\n",
        "            generation_time = pendulum.now(tz=\"UTC\").isoformat()\n",
        "\n",
        "            # Create the final report object\n",
        "            report_data = ResearchReport(\n",
        "                research_query=research_query,\n",
        "                research_summary=research_summary,\n",
        "                content_ideas=content_ideas_obj,\n",
        "                report_generated_at=generation_time\n",
        "            )\n",
        "\n",
        "            # Determine output filename\n",
        "            base_filename = dag_run.conf.get(\"output_filename_override\") if dag_run else None\n",
        "            if not base_filename:\n",
        "                 base_filename = REPORT_FILENAME\n",
        "            output_path = os.path.join(REPORT_OUTPUT_DIR, base_filename)\n",
        "\n",
        "            # Ensure output directory exists\n",
        "            os.makedirs(REPORT_OUTPUT_DIR, exist_ok=True)\n",
        "            logging.info(f\"Ensured report directory exists: {REPORT_OUTPUT_DIR}\")\n",
        "\n",
        "            # Write report data to JSON file\n",
        "            # In production: Replace this with writing to a database, cloud storage (S3/GCS), or API.\n",
        "            with open(output_path, 'w') as f:\n",
        "                # Use .model_dump_json() for Pydantic v2+\n",
        "                json.dump(report_data.model_dump(mode='json'), f, indent=4)\n",
        "\n",
        "            logging.info(f\"Successfully saved report to {output_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error during report generation or saving: {e}\", exc_info=True)\n",
        "            # Fail the task explicitly on error\n",
        "            raise AirflowFailException(f\"Report generation/saving failed: {e}\")\n",
        "\n",
        "\n",
        "    # --- Define Task Dependencies ---\n",
        "    # research_task_output holds the 'query' string returned by research_las_vegas_market\n",
        "    # but the actual agent result (summary) is implicitly passed via XComs by the SDK\n",
        "    research_task_output = research_las_vegas_market()\n",
        "\n",
        "    # The SDK automatically pushes the result of research_las_vegas_market (the summary string)\n",
        "    # via XComs and makes it available as input to the next task.\n",
        "    ideas_task_output = generate_content_ideas_from_research(research_summary=research_task_output)\n",
        "\n",
        "    # Pass the original query and the generated ideas (as dict) to the reporting task.\n",
        "    # The research_summary is implicitly passed via XComs from research_las_vegas_market.\n",
        "    report_findings(\n",
        "        research_query=research_task_output, # Pass the query explicitly\n",
        "        research_summary=research_task_output, # Pass the summary explicitly\n",
        "        ideas=ideas_task_output # Pass the ideas dict explicitly\n",
        "    )\n",
        "\n",
        "# Instantiate the DAG\n",
        "real_estate_lead_gen_dag_refined()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "XZO22iJfvR-s"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}